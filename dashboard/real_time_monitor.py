"""
Real-time 5G Network Monitoring Dashboard
Advanced web-based monitoring system with real-time updates
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import time
import json
from datetime import datetime, timedelta
import asyncio
import websockets
from src.models.predictive_network_planning.predict import make_predictions
from src.optimize import optimize_network_resources
import redis
import logging
from dataclasses import dataclass
from typing import Dict, List, Optional
import traceback

# Configure Streamlit page
st.set_page_config(
    page_title="5G OpenRAN AI Optimizer Dashboard",
    page_icon="ğŸ“¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for modern styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin: 0.5rem 0;
    }
    .status-good { color: #28a745; }
    .status-warning { color: #ffc107; }
    .status-critical { color: #dc3545; }
</style>
""", unsafe_allow_html=True)

@dataclass
class AlertConfig:
    """Configuration for real-time alerts."""
    throughput_threshold: float = 50000  # kbps
    latency_threshold: float = 10  # ms
    cpu_threshold: float = 80  # %
    energy_threshold: float = 75  # W
    alert_cooldown: int = 300  # seconds

class RealTimeDataManager:
    """Manages real-time data connections and caching."""
    
    def __init__(self):
        self.redis_client = None
        self.websocket_url = "ws://localhost:8000/ws"
        self.cache_ttl = 30  # seconds
        
        # Try to connect to Redis
        try:
            self.redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
            self.redis_client.ping()
        except (redis.ConnectionError, redis.ResponseError):
            logging.warning("Redis not available, using memory cache")
            
    def get_cached_data(self, key: str) -> Optional[Dict]:
        """Get data from cache."""
        if self.redis_client:
            try:
                data = self.redis_client.get(key)
                return json.loads(data) if data else None
            except Exception:
                return None
        return None
        
    def set_cached_data(self, key: str, data: Dict, ttl: int = None):
        """Set data in cache."""
        if self.redis_client:
            try:
                ttl = ttl or self.cache_ttl
                self.redis_client.setex(key, ttl, json.dumps(data))
            except Exception:
                pass

class AlertManager:
    """Manages real-time alerts and notifications."""
    
    def __init__(self, config: AlertConfig):
        self.config = config
        self.last_alerts = {}
        
    def check_alerts(self, metrics: Dict) -> List[Dict]:
        """Check metrics against thresholds and generate alerts."""
        alerts = []
        current_time = datetime.now()
        
        # Throughput alert
        if metrics.get('dl_throughput_mbps', 0) * 1000 < self.config.throughput_threshold:
            if self._should_alert('throughput', current_time):
                alerts.append({
                    'type': 'warning',
                    'metric': 'throughput',
                    'value': metrics['dl_throughput_mbps'] * 1000,
                    'threshold': self.config.throughput_threshold,
                    'message': f"Low throughput detected: {metrics['dl_throughput_mbps']:.1f} Mbps"
                })
                
        # Latency alert
        if metrics.get('latency_ms', 0) > self.config.latency_threshold:
            if self._should_alert('latency', current_time):
                alerts.append({
                    'type': 'error',
                    'metric': 'latency',
                    'value': metrics['latency_ms'],
                    'threshold': self.config.latency_threshold,
                    'message': f"High latency detected: {metrics['latency_ms']:.1f} ms"
                })
                
        # CPU alert
        if metrics.get('cpu_utilization', 0) > self.config.cpu_threshold:
            if self._should_alert('cpu', current_time):
                alerts.append({
                    'type': 'warning',
                    'metric': 'cpu_utilization',
                    'value': metrics['cpu_utilization'],
                    'threshold': self.config.cpu_threshold,
                    'message': f"High CPU usage: {metrics['cpu_utilization']:.1f}%"
                })
                
        return alerts
        
    def _should_alert(self, metric: str, current_time: datetime) -> bool:
        """Check if enough time has passed since last alert."""
        last_alert_time = self.last_alerts.get(metric)
        if not last_alert_time:
            self.last_alerts[metric] = current_time
            return True
            
        time_diff = (current_time - last_alert_time).total_seconds()
        if time_diff >= self.config.alert_cooldown:
            self.last_alerts[metric] = current_time
            return True
            
        return False

class RealTimeMonitor:
    def __init__(self):
        self.last_update = datetime.now()
        self.data_buffer = []
        
    def generate_real_time_data(self):
        """Generate simulated real-time 5G network data"""
        current_time = datetime.now()
        
        # Simulate 5G network metrics with realistic variations
        base_throughput = 85000 + np.random.normal(0, 15000)
        latency = max(1, np.random.exponential(8))  # Ultra-low latency for 5G
        
        # Simulate network slicing data
        slice_data = {
            'eMBB': {'throughput': base_throughput * 0.6, 'users': np.random.randint(100, 500)},
            'URLLC': {'latency': latency, 'reliability': 99.999 if latency < 5 else 99.9},
            'mMTC': {'devices': np.random.randint(1000, 10000), 'battery_life': np.random.uniform(8, 12)}
        }
        
        data = {
            'timestamp': current_time,
            'cell_id': f"5G_Cell_{np.random.randint(1, 20):02d}",
            'dl_throughput_mbps': base_throughput / 1000,
            'ul_throughput_mbps': (base_throughput * 0.4) / 1000,
            'latency_ms': latency,
            'packet_loss_percent': max(0, np.random.exponential(0.1)),
            'energy_efficiency_mbps_w': np.random.uniform(15, 25),
            'spectrum_efficiency': np.random.uniform(4.5, 7.2),
            'user_count': np.random.randint(50, 300),
            'cpu_utilization': np.random.uniform(30, 85),
            'memory_utilization': np.random.uniform(40, 80),
            'temperature_celsius': np.random.uniform(35, 65),
            'slice_data': slice_data,
            'beamforming_gain': np.random.uniform(8, 15),
            'mimo_rank': np.random.randint(2, 8),
            'carrier_aggregation_bands': np.random.randint(2, 5)
        }
        
        return data

def create_kpi_dashboard():
    """Create main KPI dashboard"""
    st.markdown('<div class="main-header">ğŸš€ 5G OpenRAN AI Optimizer - Real-Time Dashboard</div>', 
                unsafe_allow_html=True)
    
    monitor = RealTimeMonitor()
    
    # Auto-refresh setup
    if 'refresh_count' not in st.session_state:
        st.session_state.refresh_count = 0
    
    # Real-time data generation
    current_data = monitor.generate_real_time_data()
    
    # Main KPIs row
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        throughput = current_data['dl_throughput_mbps']
        status = "ğŸŸ¢" if throughput > 70 else "ğŸŸ¡" if throughput > 40 else "ğŸ”´"
        st.metric(
            label="ğŸ“Š DL Throughput",
            value=f"{throughput:.1f} Mbps",
            delta=f"{np.random.uniform(-5, 5):.1f}%"
        )
        st.markdown(f"Status: {status}")
    
    with col2:
        latency = current_data['latency_ms']
        status = "ğŸŸ¢" if latency < 5 else "ğŸŸ¡" if latency < 10 else "ğŸ”´"
        st.metric(
            label="âš¡ Latency",
            value=f"{latency:.2f} ms",
            delta=f"{np.random.uniform(-2, 2):.2f} ms"
        )
        st.markdown(f"Status: {status}")
    
    with col3:
        energy_eff = current_data['energy_efficiency_mbps_w']
        st.metric(
            label="ğŸ”‹ Energy Efficiency",
            value=f"{energy_eff:.1f} Mbps/W",
            delta=f"{np.random.uniform(-1, 3):.1f}%"
        )
    
    with col4:
        spectrum_eff = current_data['spectrum_efficiency']
        st.metric(
            label="ğŸ“¡ Spectrum Efficiency",
            value=f"{spectrum_eff:.1f} bps/Hz",
            delta=f"{np.random.uniform(-0.5, 0.8):.1f}"
        )
    
    with col5:
        users = current_data['user_count']
        st.metric(
            label="ğŸ‘¥ Active Users",
            value=f"{users:,}",
            delta=f"{np.random.randint(-20, 30)}"
        )
    
    return current_data

def create_network_slicing_view(data):
    """Create network slicing visualization"""
    st.subheader("ğŸ”€ Network Slicing Performance")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### eMBB (Enhanced Mobile Broadband)")
        embb_data = data['slice_data']['eMBB']
        st.metric("Throughput", f"{embb_data['throughput']/1000:.1f} Mbps")
        st.metric("Active Users", f"{embb_data['users']:,}")
        
    with col2:
        st.markdown("### URLLC (Ultra-Reliable Low Latency)")
        urllc_data = data['slice_data']['URLLC']
        st.metric("Latency", f"{urllc_data['latency']:.2f} ms")
        st.metric("Reliability", f"{urllc_data['reliability']:.3f}%")
        
    with col3:
        st.markdown("### mMTC (Massive Machine Type Communications)")
        mmtc_data = data['slice_data']['mMTC']
        st.metric("Connected Devices", f"{mmtc_data['devices']:,}")
        st.metric("Avg Battery Life", f"{mmtc_data['battery_life']:.1f} years")

def create_advanced_visualizations(data):
    """Create advanced visualizations"""
    st.subheader("ğŸ“ˆ Advanced Network Analytics")
    
    # Generate time series data for charts
    time_points = pd.date_range(start=datetime.now() - timedelta(hours=1), 
                               end=datetime.now(), freq='1min')
    
    # Throughput over time with prediction
    throughput_data = []
    for t in time_points:
        base = 75 + 20 * np.sin(2 * np.pi * t.hour / 24) + np.random.normal(0, 5)
        throughput_data.append(max(10, base))
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Real-time throughput chart
        fig_throughput = go.Figure()
        fig_throughput.add_trace(go.Scatter(
            x=time_points, y=throughput_data,
            mode='lines+markers',
            name='Actual Throughput',
            line=dict(color='#1f77b4', width=2)
        ))
        
        # Add prediction line
        future_points = pd.date_range(start=datetime.now(), 
                                    end=datetime.now() + timedelta(minutes=30), freq='1min')
        predicted_throughput = [throughput_data[-1] + np.random.normal(0, 2) for _ in future_points]
        
        fig_throughput.add_trace(go.Scatter(
            x=future_points, y=predicted_throughput,
            mode='lines',
            name='AI Prediction',
            line=dict(color='#ff7f0e', width=2, dash='dash')
        ))
        
        fig_throughput.update_layout(
            title="Real-time Throughput with AI Prediction",
            xaxis_title="Time",
            yaxis_title="Throughput (Mbps)",
            height=400
        )
        st.plotly_chart(fig_throughput, use_container_width=True)
    
    with col2:
        # Resource utilization heatmap
        resources = ['CPU', 'Memory', 'Network', 'Storage', 'GPU']
        time_slots = ['00:00', '06:00', '12:00', '18:00']
        utilization_matrix = np.random.uniform(30, 90, (len(resources), len(time_slots)))
        
        fig_heatmap = go.Figure(data=go.Heatmap(
            z=utilization_matrix,
            x=time_slots,
            y=resources,
            colorscale='RdYlBu_r',
            text=utilization_matrix.round(1),
            texttemplate="%{text}%",
            textfont={"size": 12}
        ))
        
        fig_heatmap.update_layout(
            title="Resource Utilization Heatmap",
            height=400
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)

def create_ai_insights_panel(data):
    """Create AI-powered insights panel"""
    st.subheader("ğŸ¤– AI-Powered Insights & Recommendations")
    
    # Generate AI insights based on current data
    insights = []
    recommendations = []
    
    if data['dl_throughput_mbps'] < 50:
        insights.append("âš ï¸ Below-average throughput detected")
        recommendations.append("ğŸ”§ Consider load balancing across multiple cells")
    
    if data['latency_ms'] > 10:
        insights.append("âš ï¸ High latency detected - may impact URLLC services")
        recommendations.append("ğŸš€ Enable edge computing for latency-sensitive applications")
    
    if data['energy_efficiency_mbps_w'] < 18:
        insights.append("ğŸ”‹ Energy efficiency below optimal threshold")
        recommendations.append("âš¡ Activate AI-driven power management algorithms")
    
    if data['cpu_utilization'] > 80:
        insights.append("ğŸ”¥ High CPU utilization detected")
        recommendations.append("ğŸ“Š Scale up computing resources or distribute load")
    
    # Always add positive insights
    insights.append("âœ… Network slicing operating within parameters")
    recommendations.append("ğŸ¯ Continue monitoring for proactive optimization")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ” Current Insights")
        for insight in insights:
            st.markdown(f"- {insight}")
    
    with col2:
        st.markdown("#### ğŸ’¡ AI Recommendations")
        for rec in recommendations:
            st.markdown(f"- {rec}")

def create_optimization_controls():
    """Create optimization control panel"""
    st.subheader("âš™ï¸ AI Optimization Controls")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ›ï¸ Auto-Optimization")
        auto_opt = st.toggle("Enable Auto-Optimization", value=True)
        if auto_opt:
            st.success("âœ… AI optimization active")
            optimization_level = st.selectbox(
                "Optimization Level",
                ["Conservative", "Balanced", "Aggressive"],
                index=1
            )
        else:
            st.warning("âš ï¸ Manual mode active")
    
    with col2:
        st.markdown("#### ğŸ“Š Thresholds")
        latency_threshold = st.slider("Max Latency (ms)", 1, 20, 5)
        throughput_threshold = st.slider("Min Throughput (Mbps)", 10, 100, 50)
        energy_threshold = st.slider("Min Energy Efficiency", 10, 30, 18)
    
    with col3:
        st.markdown("#### ğŸš¨ Alerts")
        if st.button("ğŸ”” Configure Alerts"):
            st.info("Alert configuration would open here")
        
        alert_status = st.empty()
        alert_status.success("ğŸŸ¢ All systems normal")

def create_advanced_ai_panel():
    """Create advanced AI features panel."""
    st.subheader("ğŸ§  Advanced AI Features")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”® Forecasting", "ğŸ” Anomaly Detection", "ğŸ¯ Multi-Objective Optimization", "ğŸŒ Federated Learning"])
    
    with tab1:
        st.markdown("#### ğŸ“ˆ AI-Powered Network Forecasting")
        
        # Forecasting controls
        col1, col2 = st.columns(2)
        with col1:
            forecast_horizon = st.selectbox("Forecast Horizon", ["15 minutes", "1 hour", "6 hours", "24 hours"])
            forecast_metrics = st.multiselect("Metrics to Forecast", 
                                           ["Throughput", "Latency", "Energy Usage", "User Count"],
                                           default=["Throughput", "Latency"])
        
        with col2:
            model_type = st.selectbox("AI Model", ["Transformer", "LSTM", "Prophet", "Ensemble"])
            confidence_interval = st.slider("Confidence Interval", 80, 99, 95)
        
        # Generate sample forecast
        if st.button("ğŸš€ Generate Forecast"):
            with st.spinner("Running AI forecast models..."):
                time.sleep(2)  # Simulate processing
                
                # Create forecast visualization
                future_time = pd.date_range(start=datetime.now(), periods=30, freq='15min')
                forecast_data = 80 + 10 * np.sin(np.arange(30) * 0.2) + np.random.normal(0, 3, 30)
                upper_bound = forecast_data + 5
                lower_bound = forecast_data - 5
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=future_time, y=forecast_data, name='Forecast', line=dict(color='blue')))
                fig.add_trace(go.Scatter(x=future_time, y=upper_bound, fill=None, mode='lines', line_color='rgba(0,100,80,0)', showlegend=False))
                fig.add_trace(go.Scatter(x=future_time, y=lower_bound, fill='tonexty', mode='lines', line_color='rgba(0,100,80,0)', name='Confidence Interval'))
                
                fig.update_layout(title="Network Throughput Forecast", height=400)
                st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.markdown("#### ğŸš¨ Real-time Anomaly Detection")
        
        col1, col2 = st.columns(2)
        with col1:
            sensitivity = st.slider("Detection Sensitivity", 1, 10, 7)
            detection_window = st.selectbox("Detection Window", ["1 minute", "5 minutes", "15 minutes"])
        
        with col2:
            anomaly_types = st.multiselect("Anomaly Types", 
                                         ["Performance", "Security", "Resource", "Network"],
                                         default=["Performance", "Security"])
        
        # Anomaly detection results
        st.markdown("##### Recent Anomalies Detected:")
        anomalies = [
            {"timestamp": "2025-07-03 14:23:15", "type": "Performance", "severity": "Medium", "description": "Unusual latency spike in Cell_07"},
            {"timestamp": "2025-07-03 14:18:42", "type": "Resource", "severity": "Low", "description": "Memory usage pattern deviation"},
            {"timestamp": "2025-07-03 14:12:08", "type": "Network", "severity": "High", "description": "Suspicious traffic pattern detected"}
        ]
        
        for anomaly in anomalies:
            severity_color = {"Low": "ğŸŸ¡", "Medium": "ğŸŸ ", "High": "ğŸ”´"}
            st.markdown(f"{severity_color[anomaly['severity']]} **{anomaly['type']}** | {anomaly['timestamp']} | {anomaly['description']}")
    
    with tab3:
        st.markdown("#### âš–ï¸ Multi-Objective Optimization")
        
        st.markdown("Configure optimization objectives and their weights:")
        
        col1, col2 = st.columns(2)
        with col1:
            throughput_weight = st.slider("Throughput Maximization", 0.0, 1.0, 0.3)
            latency_weight = st.slider("Latency Minimization", 0.0, 1.0, 0.3)
            energy_weight = st.slider("Energy Efficiency", 0.0, 1.0, 0.2)
        
        with col2:
            reliability_weight = st.slider("Reliability", 0.0, 1.0, 0.1)
            user_satisfaction_weight = st.slider("User Satisfaction", 0.0, 1.0, 0.1)
            
        # Pareto front visualization
        if st.button("ğŸ¯ Run Multi-Objective Optimization"):
            with st.spinner("Computing Pareto-optimal solutions..."):
                time.sleep(3)
                
                # Generate sample Pareto front
                n_solutions = 50
                throughput_vals = np.random.uniform(50, 100, n_solutions)
                energy_vals = 120 - throughput_vals + np.random.normal(0, 5, n_solutions)
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=throughput_vals, y=energy_vals, mode='markers',
                                       marker=dict(size=8, color='red'), name='Pareto Solutions'))
                fig.update_layout(title="Pareto Front: Throughput vs Energy Efficiency",
                                xaxis_title="Throughput (Mbps)", yaxis_title="Energy Efficiency",
                                height=400)
                st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.markdown("#### ğŸŒ Federated Learning Status")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Connected Sites", "12", "â†‘2")
            st.metric("Global Model Version", "v2.3.1", "Updated 2h ago")
            st.metric("Training Round", "847", "â†‘1")
        
        with col2:
            st.metric("Model Accuracy", "94.2%", "â†‘0.3%")
            st.metric("Convergence Status", "Stable", "")
            st.metric("Data Privacy", "âœ… Secured", "")
        
        # Federated learning participants
        participants = pd.DataFrame({
            'Site': [f'Site_{i:02d}' for i in range(1, 13)],
            'Data Samples': np.random.randint(1000, 5000, 12),
            'Model Accuracy': np.random.uniform(90, 96, 12),
            'Last Update': [f"{np.random.randint(1, 24)}h ago" for _ in range(12)]
        })
        
        st.markdown("##### Federated Learning Participants:")
        st.dataframe(participants, use_container_width=True)

def create_security_panel():
    """Create security monitoring panel."""
    st.subheader("ğŸ”’ Security & Compliance")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ›¡ï¸ Security Status")
        st.metric("Security Score", "98.7%", "â†‘0.2%")
        st.markdown("- âœ… All endpoints secured")
        st.markdown("- âœ… Encryption active")
        st.markdown("- âœ… Access control enforced")
        st.markdown("- âš ï¸ 2 pending updates")
    
    with col2:
        st.markdown("#### ğŸ“‹ Compliance")
        st.metric("Compliance Score", "100%", "")
        st.markdown("- âœ… 3GPP Standards")
        st.markdown("- âœ… GDPR Compliant")
        st.markdown("- âœ… ISO 27001")
        st.markdown("- âœ… NIST Framework")
    
    with col3:
        st.markdown("#### ğŸš¨ Recent Security Events")
        events = [
            "âœ… Successful authentication: Admin",
            "âš ï¸ Failed login attempt blocked",
            "âœ… Certificate renewed: api.5g-oran.com",
            "ğŸ” Security scan completed"
        ]
        for event in events:
            st.markdown(f"- {event}")

def main():
    """Main dashboard function"""
    
    # Sidebar configuration
    st.sidebar.title("ğŸ›ï¸ Dashboard Controls")
    
    refresh_rate = st.sidebar.selectbox(
        "Refresh Rate",
        ["Real-time (1s)", "5 seconds", "30 seconds", "1 minute"],
        index=0
    )
    
    show_predictions = st.sidebar.checkbox("Show AI Predictions", value=True)
    show_optimizations = st.sidebar.checkbox("Show Optimizations", value=True)
    
    # Auto-refresh
    placeholder = st.empty()
    
    with placeholder.container():
        # Main KPI dashboard
        current_data = create_kpi_dashboard()
        
        # Network slicing view
        create_network_slicing_view(current_data)
        
        # Advanced visualizations
        create_advanced_visualizations(current_data)
        
        # AI insights
        create_ai_insights_panel(current_data)
        
        # Optimization controls
        create_optimization_controls()
        
        # Advanced AI panel
        create_advanced_ai_panel()
        
        # Security panel
        create_security_panel()
        
        # Footer with last update
        st.markdown("---")
        st.markdown(f"ğŸ• Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | "
                   f"ğŸ”„ Auto-refresh: {refresh_rate}")
    
    # Auto-refresh logic
    if refresh_rate == "Real-time (1s)":
        time.sleep(1)
        st.rerun()
    elif refresh_rate == "5 seconds":
        time.sleep(5)
        st.rerun()

if __name__ == "__main__":
    main()
